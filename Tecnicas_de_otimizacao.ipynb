{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tecnicas_de_otimizacao.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**GridSearchCV**\n",
        "\n",
        "Pesquisa em Grade"
      ],
      "metadata": {
        "id": "5_ryPeuTnKr5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O Grid Seach pode ser denominado como uma versão automatizada da otimização de hiperparâmetros de pesquisa manual. A biblioteca Scikit-Learn vem com uma implementação GridSearchCV. GridSearch não é computacionalmente amigável, pois leva muito tempo para otimizar, mas pode-se ficar livre de escrever várias linhas de código.\n",
        "\n",
        "Pode-se alimentar o modelo de treinamento e a lista de hiperparâmetros em formato de dicionário para a função GridSeachCV, e seus retornos com o modelo de desempenho e sua métrica de pontuação.\n",
        "\n"
      ],
      "metadata": {
        "id": "pm7giPYVpm7k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtycpQD2mg-c"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "grid_cv = GridSearchCV(clf, param_grid, scoring=\"accuracy\", n_jobs=-1, cv=3)\n",
        "grid_cv.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Params\", grid_cv.best_params_)\n",
        "print(\"Best CV Score\", grid_cv.best_score_)\n",
        "print(f'Accuracy on Model 1 = {round(accuracy_score(y_test, grid_cv.predict(X_test)), 5)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RandomizedSearchCV**\n",
        "\n",
        "Pesquisa Randomizada"
      ],
      "metadata": {
        "id": "ftK1wRB2nb00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O Grid Search tenta todas as combinações de hiperparâmetros, aumentando assim a complexidade do tempo do cálculo. A pesquisa aleatória treina o modelo na combinação de hiperparâmetros aleatórios. O número total de combinações nas quais os vários modelos são treinados é menor para a pesquisa aleatória em comparação com a pesquisa em grade.\n",
        "\n",
        "O pacote Scikit-Learn também vem com implementação RandomSearchCV."
      ],
      "metadata": {
        "id": "HANQJvQBpt-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "grid_cv = RandomizedSearchCV(clf, param_grid, scoring=\"accuracy\", n_jobs=-1, cv=3)\n",
        "grid_cv.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Params\", grid_cv.best_params_)\n",
        "print(\"Best CV Score\", grid_cv.best_score_)\n",
        "print(f'Accuracy on Model 1 = {round(accuracy_score(y_test, grid_cv.predict(X_test)), 5)}')\n"
      ],
      "metadata": {
        "id": "frP9AwF9mo0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HalvingGridSearchCV:**\n",
        "\n",
        "Reduzindo a pesquisa de grade pela metade:"
      ],
      "metadata": {
        "id": "fojEzY-2nq-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reduzir o Grid Search à metade é uma versão otimizada da otimização de hiperparâmetros do Grid Search. Reduzir pela metade A pesquisa de grade pesquisa uma lista especificada de hiperparâmetros usando uma abordagem de redução sucessiva à metade. A estratégia de pesquisa começa avaliando todos os candidatos em uma pequena amostra dos dados e seleciona iterativamente os melhores candidatos usando amostras cada vez maiores.\n",
        "\n",
        "Reduzir a pesquisa em grade é menos dispendioso em termos computacionais do que a abordagem de pesquisa em grade. A biblioteca Scikit-Learn vem com a implementação HalvingGridSearch."
      ],
      "metadata": {
        "id": "4aQULJqmpy1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "\n",
        "halving_cv = HalvingGridSearchCV(clf, param_grid, scoring=\"accuracy\", factor=3)\n",
        "halving_cv.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Params\", halving_cv.best_params_)\n",
        "print(\"Best CV Score\", halving_cv.best_score_)\n",
        "print(f'Accuracy on Model 1 = {round(accuracy_score(y_test, halving_cv.predict(X_test)), 5)}')\n"
      ],
      "metadata": {
        "id": "SFhx7oM6mpaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reduzindo a pesquisa aleatória pela metade:**\n",
        "\n",
        "HalvingRandomSearchCV"
      ],
      "metadata": {
        "id": "RdWiogKJosJr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reduzir pela metade a pesquisa aleatória usa a mesma abordagem de redução pela metade sucessiva e é ainda mais otimizada em comparação com a redução pela metade da pesquisa de grade. Ao contrário da pesquisa de grade ao meio, ele não treina em todas as combinações de hiperparâmetros, em vez de escolher aleatoriamente um conjunto de combinações de hiperparâmetros. A biblioteca Scikit-Learn também vem com HalvingRandomizedSeachCV."
      ],
      "metadata": {
        "id": "BnNpXI7tp2S8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import HalvingRandomSearchCV\n",
        "\n",
        "halving_cv = HalvingRandomSearchCV(clf, param_grid, scoring=\"accuracy\", factor=3)\n",
        "halving_cv.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Params\", halving_cv.best_params_)\n",
        "print(\"Best CV Score\", halving_cv.best_score_)\n",
        "print(f'Accuracy on Model 1 = {round(accuracy_score(y_test, halving_cv.predict(X_test)), 5)}')\n"
      ],
      "metadata": {
        "id": "vMhgL953o6mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperopt-Sklearn:**"
      ],
      "metadata": {
        "id": "6ffBLeqEo6Na"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperopt é uma biblioteca Python de código aberto para Otimização Bayesiana, projetada para otimizações em grande escala de modelos com centenas de parâmetros. Ele permite que a otimização do hiperparâmetro seja dimensionada em vários núcleos da CPU.\n",
        "\n",
        "Hyperopt-Sklearn é uma extensão da biblioteca Hyperopt, que permite a pesquisa automática de algoritmos de aprendizado de máquina e hiperparâmetros de modelo para tarefas de classificação e regressão."
      ],
      "metadata": {
        "id": "19INP4zSp6tO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bayes Grid Search:**"
      ],
      "metadata": {
        "id": "JvhJ_yTWpF7q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O Bayes Grid Search usa a técnica de otimização bayesiana para modelar o espaço de busca para chegar aos valores dos parâmetros otimizados o mais rápido possível. Ele usa a estrutura do espaço de busca para otimizar o tempo de busca. A abordagem do Bayes Search usa os resultados da avaliação anterior para criar uma amostra de novos candidatos com maior probabilidade de apresentar melhores resultados.\n",
        "\n",
        "A biblioteca Scikit-Optimize vem com implementação BayesSearchCV."
      ],
      "metadata": {
        "id": "xbkMANkhp_HM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "# parameter ranges are specified by one of below\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "\n",
        "\n",
        "# Pipeline parameters search spaces\n",
        "search_spaces = {\"vect__max_features\": Integer(1000, 1500),\n",
        "                 \"vect__max_df\": Real(0, 1, prior='uniform'),\n",
        "                 \"clf__n_estimators\": Integer(200,  400)}\n",
        "\n",
        "# Bayesian grid search on the pipeline\n",
        "opt = BayesSearchCV(model, search_spaces, cv=3)\n",
        "opt.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "1V7KYBlhmpnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ss0JPL3Emptv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gQYejssompzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QrgkkXYdmp4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AGiQvmMImp7s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}